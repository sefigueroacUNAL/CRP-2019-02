{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje Supervisado - Naive Bayes (Bayes Ingenuo)\n",
    "\n",
    "Los clasificadores de Bayes ingenuos son clasificadores lineales conocidos por su simpleza y eficiencia. El modelo probabilístico de los clasificadores de Bayes ingenuos se basa en el Teorema de Bayes y el adjetivo *ingenuo* viene de la suposición  de que las características en la base de datos son mutuamente independientes.\n",
    "\n",
    "![Naive Bayes](imagenes/Bayes.png)\n",
    "\n",
    "En la práctica, la suposición de independencia se viola frecuentemente, pero el clasificador de Bayes ingenuo tiende a tener un buen desempeño aún bajo esta suposición poco realista, especialmente para tamaños pequeños de muestra.\n",
    "\n",
    "Este clasificador está construido con base en la probabilidad a posteriori, la cuál está definida por el teorema de Bayes de la siguiente manera:<br/><br/>\n",
    "\n",
    "$$ P_{a-posteriori} = \\frac{P_{condicional} \\times P_{a-priori}}{evicencia}$$\n",
    "\n",
    "En clasificación esto es:<br/><br/>\n",
    "$$P(\\omega_j|\\mathbf{x}_i)=\\frac{P(\\mathbf{x}_i|\\omega_j)P(\\omega_j)}{P(\\mathbf{x}_i)}$$\n",
    "\n",
    "La función objetivo en la probabilidad de Bayes ingenuo, es maximizar la probabilidad a posteriori dado el conjunto de entrenamiento, en orden de formular la regla de decisión.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np    #Para el manejo de arreglos\n",
    "import pandas as pd   #Para el manejo de conjuntos de datos, tratados como tablas\n",
    "import seaborn as sns #Para la construcción y visualización de gráficos\n",
    "import matplotlib.pyplot as plt #Pra la construcción de gráficos\n",
    "\n",
    "from sklearn import naive_bayes #importamos la librería que contiene el clasificador de Bayes\n",
    "from sklearn import metrics #Las métricas de rendimiento de un clasificador\n",
    "from sklearn import model_selection #Para el particionamiento de los conjuntos de datos\n",
    "from sklearn import datasets #Conjuntos de datos predefinidos en sklearn\n",
    "from sklearn import preprocessing #Nos ayuda a convertir características categóricas a numéricas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Veámos un ejemplo Básico\n",
    "\n",
    "Vamos a empezar con un ejemplo básico, el cual consiste en determinar si un jugador jugará un partido con base en las condiciones del clima y la temperatura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Crear el conjunto de datos\n",
    "\n",
    " Empecemos construyendo el conjunto de datos de juguete (toy set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos tres vectores: 2 con las características y el otr con las etiquetas\n",
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny','Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que las característcias son categóricas, debemos transformar estas a valores numéricos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el codificador\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "#Convertimos las etiquetas a números\n",
    "weather2 = le.fit_transform(weather)\n",
    "temp2 = le.fit_transform(temp)\n",
    "y = le.fit_transform(play)\n",
    "\n",
    "print (\"Etiquetas: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los vectores creamos la matriz de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([weather2.T, temp2.T])\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Entrenamos el modelo\n",
    "\n",
    "Note que en sklearn los modelos para Naive Bayes se diferencian unos de otros dependiendo de como estiman la probabilidad $P(x_i|c_j)$. En este caso usamos la versión que estima dicha probabilidad asumiendo una Gaussiana Univariada, cuyos parámetros se estiman a partir de la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos el modelo\n",
    "nv = naive_bayes.GaussianNB()\n",
    "\n",
    "# Entrenamos el modelo\n",
    "nv.fit(X,y)\n",
    "\n",
    "print (\"Media de cada característica, por clase: \\n\", nv.theta_)\n",
    "print (\"\\nVarianza de cada característica, por clase:\\n\", nv.sigma_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Usamos el modelo para hacer una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecimos si el jugador va a jugar considerando que las características Weather 0:Overcast, Temp 2:Mild\n",
    "predicted = nv.predict([[0,2]])\n",
    "\n",
    "print (\"Valor que se predice:\", predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hagamos un ejercicio con unos datos simulados\n",
    "\n",
    "Realiza las gráficas de la matriz de observaciones con todas las posibles combinaciones de las características (e.j. Característica 1 vs Característica 2, Característica 1 vs Característica 3, etc). Asegúrate de que cada una de las clases se vea de un color diferente para saber cuáles características serían mejores para clasificar (las que sean linealmente separables). Para esto use seaborn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero importamos el archivo de datos que contiene el conjunto de entrenamiento.\n",
    "#Use la función read_csv de pandas \n",
    "dataset = pd.read_csv('datos/Data_NaiveBayes.txt')\n",
    "\n",
    "# Usamos el paquete seaborn para visualizar las características\n",
    "# Use la función pairplot para mostrar las características de a pares\n",
    "# vars=dataset.columns[:-1] : Elimina la clase de las características a plotear\n",
    "# hue=\"y\" : Esto indica cual es el atributo que representa la clase \n",
    "# diag_kind='kde' : esto indica que en la diagonal se muestra una estimación de la PDF de la característica\n",
    "# markers=[\"o\", \"^\", \"x\", \"s\"] : define los marcadores para cada clase\n",
    "# palette=\"muted\" : establece la paleta de colores\n",
    "\n",
    "sns.pairplot(dataset, vars=dataset.columns[:-1], diag_kind='kde', hue=\"y\", markers=[\"o\", \"^\", \"x\", \"s\"], palette=\"muted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:10px; border-radius:10px; border:2px solid #4BACC6; background:#EEEEEE\">\n",
    "<span style=\"color:#4BACC6\" ><h3>**Para Tener en Cuenta:**</h3></span> <h4>¿Son todas las caracteristicas de este conjunto de datos relevantes?, ¿Por qué? </h4></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, proceda a particionar el conjunto de datos para entrenamiento y validación usando 70% y 30%, respectivamente. Adicionalmente, normalice los datos usando un StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenga X e y del DataFrame\n",
    "X = dataset.values[:,:-1]\n",
    "y = dataset.values[:,-1]\n",
    "\n",
    "#Separe el conjunto en dos partes: una para entrenar y otra para validar\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Normalice con base en el conjunto de entrenamiento\n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(X_train)\n",
    "\n",
    "X_train_std = scl.transform(X_train)\n",
    "X_test_std = scl.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a entrenar el modelo. En este caso, usaremos un clasificador Bayesiano Ingenuo, asumiendo distribuciones Gaussianas sobre cada característica de manera individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defina el modelo del clasificador\n",
    "nv = naive_bayes.GaussianNB()\n",
    "\n",
    "#Entrene el clasificador usando el conjunto de entrenamiento preprocesado\n",
    "nv.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, procedemos a evaluar el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir la clase del conjunto de test\n",
    "y_pred = nv.predict(X_test_std)\n",
    "\n",
    "#Calcule la precisión y muestre la matriz de confusión\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print (\"Precisión del clasificador: %.2f \" %(acc*100.0) )\n",
    "print (\"\\nMatriz de Confusión: \\n\", mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, utiliza como matriz de observaciones $\\mathbf{X}$ el conjunto de todas las observaciones pero **únicamente** con las dos combinaciones de características que consideras mejor separan las clases de acuerdo a las gráficas del **ejercicio anterior**. Preprocesa, particiona y clasifica con esa nueva matriz de observaciones. ¿Funciona mejor o peor el clasificador?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codifique la solución aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hagamos un ejercicio con un conjunto de datos real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el conjunto de datos desde Sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo se puede observar, el conjunto de datos está almacenado en un diccionario, así que debemos separar los tres elementos que nos importan de él:\n",
    "- X: la matriz de datos\n",
    "- y: el vector de etiquetas\n",
    "- Xn: los nombres de las características\n",
    "\n",
    "Tenga presente que las calses Benigno (0) y Maligno (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos el dataset\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "Xn = data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora particionamos el conjunto de datos en dos partes: una para entrenar y otra para validar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a entrenamos el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define el modelo del clasificador a entrenar\n",
    "nv = naive_bayes.GaussianNB()\n",
    "\n",
    "#Se entrena el clasificador usando el conjunto de entrenamiento preprocesado\n",
    "nv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, evaluamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir la clase del conjunto de test\n",
    "y_pred = nv.predict(X_test)\n",
    "\n",
    "#Calcule la precisión y muestre la matriz de confusión\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print (\"Precisión del clasificador: %.2f \" %(acc*100.0) )\n",
    "print (\"\\nMatriz de Confusión: \\n\", mat)\n",
    "\n",
    "\n",
    "#Esta es otra forma de ver la matriz de confusión\n",
    "sns.heatmap(mat, square=True, annot=True, fmt=\"d\", cbar=False, cmap=\"Blues\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
